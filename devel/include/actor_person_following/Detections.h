// Generated by gencpp from file actor_person_following/Detections.msg
// DO NOT EDIT!


#ifndef ACTOR_PERSON_FOLLOWING_MESSAGE_DETECTIONS_H
#define ACTOR_PERSON_FOLLOWING_MESSAGE_DETECTIONS_H


#include <string>
#include <vector>
#include <map>

#include <ros/types.h>
#include <ros/serialization.h>
#include <ros/builtin_message_traits.h>
#include <ros/message_operations.h>

#include <std_msgs/Header.h>
#include <std_msgs/Header.h>
#include <sensor_msgs/Image.h>
#include <actor_person_following/Detection.h>
#include <perception_msgs/PointInImage.h>

namespace actor_person_following
{
template <class ContainerAllocator>
struct Detections_
{
  typedef Detections_<ContainerAllocator> Type;

  Detections_()
    : header()
    , image_header()
    , image()
    , num_detects(0)
    , detections()
    , closest(0)
    , close_target(0)
    , aruco_target(0)
    , color_target(0)
    , xres(0)
    , yres(0)
    , aruco_visible(false)
    , aruco_x(0.0)
    , aruco_y(0.0)
    , aruco_points()
    , start(false)
    , stop(false)  {
    }
  Detections_(const ContainerAllocator& _alloc)
    : header(_alloc)
    , image_header(_alloc)
    , image(_alloc)
    , num_detects(0)
    , detections(_alloc)
    , closest(0)
    , close_target(0)
    , aruco_target(0)
    , color_target(0)
    , xres(0)
    , yres(0)
    , aruco_visible(false)
    , aruco_x(0.0)
    , aruco_y(0.0)
    , aruco_points(_alloc)
    , start(false)
    , stop(false)  {
  (void)_alloc;
    }



   typedef  ::std_msgs::Header_<ContainerAllocator>  _header_type;
  _header_type header;

   typedef  ::std_msgs::Header_<ContainerAllocator>  _image_header_type;
  _image_header_type image_header;

   typedef  ::sensor_msgs::Image_<ContainerAllocator>  _image_type;
  _image_type image;

   typedef int32_t _num_detects_type;
  _num_detects_type num_detects;

   typedef std::vector< ::actor_person_following::Detection_<ContainerAllocator> , typename ContainerAllocator::template rebind< ::actor_person_following::Detection_<ContainerAllocator> >::other >  _detections_type;
  _detections_type detections;

   typedef int32_t _closest_type;
  _closest_type closest;

   typedef int32_t _close_target_type;
  _close_target_type close_target;

   typedef int32_t _aruco_target_type;
  _aruco_target_type aruco_target;

   typedef int32_t _color_target_type;
  _color_target_type color_target;

   typedef int32_t _xres_type;
  _xres_type xres;

   typedef int32_t _yres_type;
  _yres_type yres;

   typedef uint8_t _aruco_visible_type;
  _aruco_visible_type aruco_visible;

   typedef double _aruco_x_type;
  _aruco_x_type aruco_x;

   typedef double _aruco_y_type;
  _aruco_y_type aruco_y;

   typedef std::vector< ::perception_msgs::PointInImage_<ContainerAllocator> , typename ContainerAllocator::template rebind< ::perception_msgs::PointInImage_<ContainerAllocator> >::other >  _aruco_points_type;
  _aruco_points_type aruco_points;

   typedef uint8_t _start_type;
  _start_type start;

   typedef uint8_t _stop_type;
  _stop_type stop;





  typedef boost::shared_ptr< ::actor_person_following::Detections_<ContainerAllocator> > Ptr;
  typedef boost::shared_ptr< ::actor_person_following::Detections_<ContainerAllocator> const> ConstPtr;

}; // struct Detections_

typedef ::actor_person_following::Detections_<std::allocator<void> > Detections;

typedef boost::shared_ptr< ::actor_person_following::Detections > DetectionsPtr;
typedef boost::shared_ptr< ::actor_person_following::Detections const> DetectionsConstPtr;

// constants requiring out of line definition



template<typename ContainerAllocator>
std::ostream& operator<<(std::ostream& s, const ::actor_person_following::Detections_<ContainerAllocator> & v)
{
ros::message_operations::Printer< ::actor_person_following::Detections_<ContainerAllocator> >::stream(s, "", v);
return s;
}


template<typename ContainerAllocator1, typename ContainerAllocator2>
bool operator==(const ::actor_person_following::Detections_<ContainerAllocator1> & lhs, const ::actor_person_following::Detections_<ContainerAllocator2> & rhs)
{
  return lhs.header == rhs.header &&
    lhs.image_header == rhs.image_header &&
    lhs.image == rhs.image &&
    lhs.num_detects == rhs.num_detects &&
    lhs.detections == rhs.detections &&
    lhs.closest == rhs.closest &&
    lhs.close_target == rhs.close_target &&
    lhs.aruco_target == rhs.aruco_target &&
    lhs.color_target == rhs.color_target &&
    lhs.xres == rhs.xres &&
    lhs.yres == rhs.yres &&
    lhs.aruco_visible == rhs.aruco_visible &&
    lhs.aruco_x == rhs.aruco_x &&
    lhs.aruco_y == rhs.aruco_y &&
    lhs.aruco_points == rhs.aruco_points &&
    lhs.start == rhs.start &&
    lhs.stop == rhs.stop;
}

template<typename ContainerAllocator1, typename ContainerAllocator2>
bool operator!=(const ::actor_person_following::Detections_<ContainerAllocator1> & lhs, const ::actor_person_following::Detections_<ContainerAllocator2> & rhs)
{
  return !(lhs == rhs);
}


} // namespace actor_person_following

namespace ros
{
namespace message_traits
{





template <class ContainerAllocator>
struct IsMessage< ::actor_person_following::Detections_<ContainerAllocator> >
  : TrueType
  { };

template <class ContainerAllocator>
struct IsMessage< ::actor_person_following::Detections_<ContainerAllocator> const>
  : TrueType
  { };

template <class ContainerAllocator>
struct IsFixedSize< ::actor_person_following::Detections_<ContainerAllocator> >
  : FalseType
  { };

template <class ContainerAllocator>
struct IsFixedSize< ::actor_person_following::Detections_<ContainerAllocator> const>
  : FalseType
  { };

template <class ContainerAllocator>
struct HasHeader< ::actor_person_following::Detections_<ContainerAllocator> >
  : TrueType
  { };

template <class ContainerAllocator>
struct HasHeader< ::actor_person_following::Detections_<ContainerAllocator> const>
  : TrueType
  { };


template<class ContainerAllocator>
struct MD5Sum< ::actor_person_following::Detections_<ContainerAllocator> >
{
  static const char* value()
  {
    return "89334e354050dfb15aacf14eca62859b";
  }

  static const char* value(const ::actor_person_following::Detections_<ContainerAllocator>&) { return value(); }
  static const uint64_t static_value1 = 0x89334e354050dfb1ULL;
  static const uint64_t static_value2 = 0x5aacf14eca62859bULL;
};

template<class ContainerAllocator>
struct DataType< ::actor_person_following::Detections_<ContainerAllocator> >
{
  static const char* value()
  {
    return "actor_person_following/Detections";
  }

  static const char* value(const ::actor_person_following::Detections_<ContainerAllocator>&) { return value(); }
};

template<class ContainerAllocator>
struct Definition< ::actor_person_following::Detections_<ContainerAllocator> >
{
  static const char* value()
  {
    return "Header header\n"
"Header image_header\n"
"sensor_msgs/Image image\n"
"int32 num_detects\n"
"Detection[] detections\n"
"\n"
"int32 closest\n"
"int32 close_target\n"
"int32 aruco_target\n"
"int32 color_target\n"
"\n"
"int32 xres\n"
"int32 yres\n"
"\n"
"bool aruco_visible\n"
"float64 aruco_x\n"
"float64 aruco_y\n"
"perception_msgs/PointInImage[] aruco_points\n"
"\n"
"bool start\n"
"bool stop\n"
"\n"
"================================================================================\n"
"MSG: std_msgs/Header\n"
"# Standard metadata for higher-level stamped data types.\n"
"# This is generally used to communicate timestamped data \n"
"# in a particular coordinate frame.\n"
"# \n"
"# sequence ID: consecutively increasing ID \n"
"uint32 seq\n"
"#Two-integer timestamp that is expressed as:\n"
"# * stamp.sec: seconds (stamp_secs) since epoch (in Python the variable is called 'secs')\n"
"# * stamp.nsec: nanoseconds since stamp_secs (in Python the variable is called 'nsecs')\n"
"# time-handling sugar is provided by the client library\n"
"time stamp\n"
"#Frame this data is associated with\n"
"string frame_id\n"
"\n"
"================================================================================\n"
"MSG: sensor_msgs/Image\n"
"# This message contains an uncompressed image\n"
"# (0, 0) is at top-left corner of image\n"
"#\n"
"\n"
"Header header        # Header timestamp should be acquisition time of image\n"
"                     # Header frame_id should be optical frame of camera\n"
"                     # origin of frame should be optical center of camera\n"
"                     # +x should point to the right in the image\n"
"                     # +y should point down in the image\n"
"                     # +z should point into to plane of the image\n"
"                     # If the frame_id here and the frame_id of the CameraInfo\n"
"                     # message associated with the image conflict\n"
"                     # the behavior is undefined\n"
"\n"
"uint32 height         # image height, that is, number of rows\n"
"uint32 width          # image width, that is, number of columns\n"
"\n"
"# The legal values for encoding are in file src/image_encodings.cpp\n"
"# If you want to standardize a new string format, join\n"
"# ros-users@lists.sourceforge.net and send an email proposing a new encoding.\n"
"\n"
"string encoding       # Encoding of pixels -- channel meaning, ordering, size\n"
"                      # taken from the list of strings in include/sensor_msgs/image_encodings.h\n"
"\n"
"uint8 is_bigendian    # is this data bigendian?\n"
"uint32 step           # Full row length in bytes\n"
"uint8[] data          # actual matrix data, size is (step * rows)\n"
"\n"
"================================================================================\n"
"MSG: actor_person_following/Detection\n"
"float64 width\n"
"float64 height\n"
"float64 center\n"
"\n"
"float64 close_overlap\n"
"float64 aruco_overlap\n"
"\n"
"float64 close_dist\n"
"float64 aruco_dist\n"
"\n"
"float64 aruco_strength\n"
"\n"
"float32 r\n"
"float32 g\n"
"float32 b\n"
"\n"
"string gesture\n"
"actor_person_following/Pose_Points pose_points\n"
"\n"
"darknet_ros_msgs/BoundingBox box\n"
"actor_person_following/Lidar_Point lidar_point\n"
"\n"
"================================================================================\n"
"MSG: actor_person_following/Pose_Points\n"
"actor_person_following/Pose_Point[] points\n"
"\n"
"================================================================================\n"
"MSG: actor_person_following/Pose_Point\n"
"float64 x\n"
"float64 y\n"
"int32 frame_x\n"
"int32 frame_y\n"
"\n"
"================================================================================\n"
"MSG: darknet_ros_msgs/BoundingBox\n"
"float64 probability\n"
"int64 xmin\n"
"int64 ymin\n"
"int64 xmax\n"
"int64 ymax\n"
"int16 id\n"
"string Class\n"
"\n"
"================================================================================\n"
"MSG: actor_person_following/Lidar_Point\n"
"float64 x\n"
"float64 y\n"
"float64 z\n"
"\n"
"float64 distance\n"
"float64 pitch\n"
"float64 yaw\n"
"\n"
"float64 frame_x\n"
"float64 frame_y\n"
"\n"
"================================================================================\n"
"MSG: perception_msgs/PointInImage\n"
"# x coordinate of the point in the image\n"
"float32 x\n"
"# y coordinate of the poitn in the image\n"
"float32 y\n"
;
  }

  static const char* value(const ::actor_person_following::Detections_<ContainerAllocator>&) { return value(); }
};

} // namespace message_traits
} // namespace ros

namespace ros
{
namespace serialization
{

  template<class ContainerAllocator> struct Serializer< ::actor_person_following::Detections_<ContainerAllocator> >
  {
    template<typename Stream, typename T> inline static void allInOne(Stream& stream, T m)
    {
      stream.next(m.header);
      stream.next(m.image_header);
      stream.next(m.image);
      stream.next(m.num_detects);
      stream.next(m.detections);
      stream.next(m.closest);
      stream.next(m.close_target);
      stream.next(m.aruco_target);
      stream.next(m.color_target);
      stream.next(m.xres);
      stream.next(m.yres);
      stream.next(m.aruco_visible);
      stream.next(m.aruco_x);
      stream.next(m.aruco_y);
      stream.next(m.aruco_points);
      stream.next(m.start);
      stream.next(m.stop);
    }

    ROS_DECLARE_ALLINONE_SERIALIZER
  }; // struct Detections_

} // namespace serialization
} // namespace ros

namespace ros
{
namespace message_operations
{

template<class ContainerAllocator>
struct Printer< ::actor_person_following::Detections_<ContainerAllocator> >
{
  template<typename Stream> static void stream(Stream& s, const std::string& indent, const ::actor_person_following::Detections_<ContainerAllocator>& v)
  {
    s << indent << "header: ";
    s << std::endl;
    Printer< ::std_msgs::Header_<ContainerAllocator> >::stream(s, indent + "  ", v.header);
    s << indent << "image_header: ";
    s << std::endl;
    Printer< ::std_msgs::Header_<ContainerAllocator> >::stream(s, indent + "  ", v.image_header);
    s << indent << "image: ";
    s << std::endl;
    Printer< ::sensor_msgs::Image_<ContainerAllocator> >::stream(s, indent + "  ", v.image);
    s << indent << "num_detects: ";
    Printer<int32_t>::stream(s, indent + "  ", v.num_detects);
    s << indent << "detections[]" << std::endl;
    for (size_t i = 0; i < v.detections.size(); ++i)
    {
      s << indent << "  detections[" << i << "]: ";
      s << std::endl;
      s << indent;
      Printer< ::actor_person_following::Detection_<ContainerAllocator> >::stream(s, indent + "    ", v.detections[i]);
    }
    s << indent << "closest: ";
    Printer<int32_t>::stream(s, indent + "  ", v.closest);
    s << indent << "close_target: ";
    Printer<int32_t>::stream(s, indent + "  ", v.close_target);
    s << indent << "aruco_target: ";
    Printer<int32_t>::stream(s, indent + "  ", v.aruco_target);
    s << indent << "color_target: ";
    Printer<int32_t>::stream(s, indent + "  ", v.color_target);
    s << indent << "xres: ";
    Printer<int32_t>::stream(s, indent + "  ", v.xres);
    s << indent << "yres: ";
    Printer<int32_t>::stream(s, indent + "  ", v.yres);
    s << indent << "aruco_visible: ";
    Printer<uint8_t>::stream(s, indent + "  ", v.aruco_visible);
    s << indent << "aruco_x: ";
    Printer<double>::stream(s, indent + "  ", v.aruco_x);
    s << indent << "aruco_y: ";
    Printer<double>::stream(s, indent + "  ", v.aruco_y);
    s << indent << "aruco_points[]" << std::endl;
    for (size_t i = 0; i < v.aruco_points.size(); ++i)
    {
      s << indent << "  aruco_points[" << i << "]: ";
      s << std::endl;
      s << indent;
      Printer< ::perception_msgs::PointInImage_<ContainerAllocator> >::stream(s, indent + "    ", v.aruco_points[i]);
    }
    s << indent << "start: ";
    Printer<uint8_t>::stream(s, indent + "  ", v.start);
    s << indent << "stop: ";
    Printer<uint8_t>::stream(s, indent + "  ", v.stop);
  }
};

} // namespace message_operations
} // namespace ros

#endif // ACTOR_PERSON_FOLLOWING_MESSAGE_DETECTIONS_H
